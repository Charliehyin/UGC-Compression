# Investigating Selective Video Compression in User-Generated Content Delivery Platforms
By Charlie Yin and Andrew Yang 
## Introduction
With the rising popularity of social media and video-sharing platforms like YouTube and TikTok, user-generated content (UGC) have exploded in popularity, and as such, their effect on internet network infrastructure has likewise exploded. One technique that has become commonplace in managing UGC’s effect on networks is video compression. However, while compression does effectively reduce the size and bandwidth requirements of UGC, it comes at the cost of video quality. This is particularly concerning for creators that have used expensive, high quality camera equipment, only for their video quality to be reduced by compression. 
One key feature of compression is that it is highly CPU intensive. As such, it is not optimal compute-wise for all videos to be compressed. As such, compression is not applied uniformly across all videos. Variables such as video length, perceived popularity, user subscription status, and engagement metrics all affect the compression of videos. This inequity amongst video compression raises fairness and transparency concerns, especially when certain creators or video types end up with consistently lower video quality. In addition, it could raise concerns if “HD” quality varies between free and premium users of video-sharing platforms. 
The goal of our research is to investigate these compression strategies and trends, and evaluate their impact on user experience and creator equity. Through techniques including quality assessment, data mining, and real-time monitoring, we hope to create transparency in compression patterns used by popular video-sharing platforms. Primarily, we want to figure out whether compression patterns used by such platforms prioritize costs over content quality. 
Key questions include:
* Is the same resolution (e.g., 1080p) truly equivalent across user tiers (free vs premium)?
* Is how much a video is compressed influenced by attributes like video length, popularity, or creator status?
* Can artificially boosted “popularity” (e.g. views, subscribers) be detected through discrepancies in compression behavior?

To address these questions, we propose the following methodologies:
* Randomized Video Quality Monitoring: Randomly sample videos across different categories, and track the quality of the video. 
* Revisit sample videos over time, to learn how video quality changes over time
* Controlled Video Uploads: Upload videos with known characteristics such as length, resolution, or bitrate. 
* Compare differences in quality post-upload, to learn how the different characteristics affect video quality. 
* Browser Plugin Tool: Create a browser plugin that can collect video metadata in real time. 
* This plugin will alert users when the video they are watching/posting is likely to experience excessive compression. 
To effectively and accurately measure video quality, we plan to utilize VMAF (Video Multi-method Assessment Fusion) by Netflix and UVQ (Universal Video Quality) by Google. 

## Motivation
Video compression isn’t solely a technical detail - it directly affects how users perceive and engage with content. When creators invest in high-end equipment to make professional-quality videos, and platforms silently degrade said videos through unknown compression methods, it creates a direct mismatch between creator effort and viewer experience. This mismatch can discourage creators from the platform and reduce trust in the platform’s fairness. More importantly, when the same resolution label, such as 1080p can mean different things depending on the viewer’s account or the perceived popularity of a video, it misleads users and undermines transparency.
By understanding how and why compression decisions are made, we can expose hidden inequalities and give users and creators far more control over their content experience. If these strategies disproportionately affect certain types of users, such as smaller creators or non-premium viewers, there are questions to be raised about digital equity, platform accountability, and informed consent. By investigating these practices, we’re not only addressing a technical issue, but also taking a look into a broader problem of algorithmic fairness and platform responsibility in the booming age of user-generated content.

## Related Work
Related work for this project includes papers like UVQ: Measuring YouTube's Perceptual Video Quality. This paper, from Google Research, investigates how video compression affects perceptual video quality. While compression may lower video quality, a user's subjective perception of video quality is likewise important. They introduce UVQ, a tool that generates a report with quality scores and insights that can be used to interpret UGC video perceptual quality. Other similar tools include VMAF. 
VMAF (Video Multi-method Assessment Fusion) by Netflix is another widely used tool for assessing perceptual video quality. VMAF combines multiple basic quality metrics using machine learning to produce a single quality score that closely aligns with human visual perception. It’s become an industry standard for evaluating video streaming quality and is particularly valuable because it considers both technical factors such as resolution and bitrate, as well as subjective human experience. In our project, we plan to leverage VMAF and UVQ to objectively determine the quality of UGC posted to video-sharing platforms. This will help us evaluate the extent of compression on UGC from different user groups or content types.
Another resource we found is YouTube’s UGC dataset, which is a sampling from thousands of UGC as uploaded to YouTube distributed under the Creative Commons license. This dataset can be helpful in determining a benchmark for original video quality of UGC, without any additional compression from video-sharing platforms. Papers such as https://arxiv.org/abs/1904.06457 have used this dataset to evaluate video quality of UGC. 
Papers such as Compression Level Analysis: Examining Video Recompression Levels have evaluated how YouTube’s compression algorithm changes the level of compression depending on different video editing and encoding software. While this is an old paper, and their findings may be outdated, many of the techniques used may still be useful to us today. 
The cost of uploading a video to social media explained: the inefficiency of current video compression algorithms investigates the economic and environmental cost of uploading a video onto platforms such as TikTok or Youtube. They found that “video compression algorithms are among the key elements that need to be optimized to increase energy efficiency in the design of these widely used applications.” They have detailed statistics on the processing time and size reduction for various video compression codecs used by these platforms. 